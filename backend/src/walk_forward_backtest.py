"""
walk_forward_backtest.py

Walk-Forward Backtest cho mÃ´ hÃ¬nh dá»± bÃ¡o nÄƒng suáº¥t cÃ  phÃª Äáº¯k Láº¯k
Backtest 7 nÄƒm gáº§n nháº¥t, má»—i láº§n dá»± Ä‘oÃ¡n 1 nÄƒm mÃ  mÃ´ hÃ¬nh chÆ°a tá»«ng tháº¥y yield nÄƒm Ä‘Ã³.

Quy trÃ¬nh Walk-Forward:
- NÄƒm N: Train trÃªn data < N, predict nÄƒm N
- Láº·p láº¡i cho 7 nÄƒm gáº§n nháº¥t
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

# ========================
# Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN
# ========================
BASE_DIR = Path(__file__).parent.parent
DATA_RAW = BASE_DIR / "data" / "raw"
DATA_PROCESSED = BASE_DIR / "data" / "processed"
MODELS_DIR = BASE_DIR / "models"

# Files
FEATURES_FILE = DATA_PROCESSED / "features_yearly.csv"
YIELD_FILE = DATA_RAW / "coffee_yield_daklak.csv"

# Output files
BACKTEST_CSV = DATA_PROCESSED / "backtest_walk_forward.csv"
PLOT_ACTUAL_VS_PRED = MODELS_DIR / "wf_actual_vs_predicted.png"
PLOT_ERROR_PER_YEAR = MODELS_DIR / "wf_error_per_year.png"

# Features to use
FEATURE_COLUMNS = [
    "rain_Feb_Mar",
    "soil_Apr_Jun",
    "temp_max_MayJun",
    "days_over_33",
    "radiation_JunSep",
    "rain_OctDec",
    "humidity_Apr_Jun",
    "SPI_MarJun",
]

# XGBoost hyperparameters
XGB_PARAMS = {
    'n_estimators': 500,
    'learning_rate': 0.05,
    'max_depth': 4,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'random_state': 42,
    'n_jobs': -1
}


def calculate_mape(y_true, y_pred):
    """Calculate Mean Absolute Percentage Error."""
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100


def walk_forward_backtest():
    """
    Thá»±c hiá»‡n Walk-Forward Backtest cho 7 nÄƒm gáº§n nháº¥t.
    """
    print("=" * 80)
    print("ğŸ”„ WALK-FORWARD BACKTEST - Dá»° BÃO NÄ‚NG SUáº¤T CÃ€ PHÃŠ Äáº®K Láº®K")
    print("=" * 80)
    
    # ===========================
    # 1. LOAD DATA
    # ===========================
    print("\nğŸ“‚ Step 1: Loading data...")
    
    features_df = pd.read_csv(FEATURES_FILE)
    yield_df = pd.read_csv(YIELD_FILE)
    
    # Merge features with yield
    df = features_df.merge(yield_df[['year', 'yield_ton_ha']], on='year', how='inner')
    df = df.sort_values('year').reset_index(drop=True)
    
    print(f"   Total years with yield data: {len(df)}")
    print(f"   Years available: {list(df['year'].values)}")
    
    # ===========================
    # 2. XÃC Äá»ŠNH 7 NÄ‚M Gáº¦N NHáº¤T
    # ===========================
    print("\nğŸ“… Step 2: Identifying 7 most recent years for backtest...")
    
    all_years = sorted(df['year'].values)
    backtest_years = all_years[-7:]  # 7 nÄƒm cuá»‘i
    
    print(f"   âœ… Backtest years: {backtest_years}")
    print(f"   âœ… Training will use data from years < each backtest year")
    
    # ===========================
    # 3. WALK-FORWARD VALIDATION
    # ===========================
    print("\nğŸ§  Step 3: Performing Walk-Forward Validation...")
    print("-" * 80)
    
    results = []
    feature_importances = []
    
    for year_n in backtest_years:
        print(f"\n   ğŸ“ Backtesting Year {year_n}:")
        
        # BÆ°á»›c 1: Táº¡o training data (all years < N)
        train_mask = df['year'] < year_n
        df_train = df[train_mask].copy()
        
        X_train = df_train[FEATURE_COLUMNS]
        y_train = df_train['yield_ton_ha']
        
        print(f"      Train: {len(df_train)} years ({df_train['year'].min()}-{df_train['year'].max()})")
        
        # BÆ°á»›c 2: Táº¡o test data (only year N)
        test_mask = df['year'] == year_n
        df_test = df[test_mask].copy()
        
        X_test = df_test[FEATURE_COLUMNS]
        y_real = df_test['yield_ton_ha'].values[0]
        
        # BÆ°á»›c 3: Train model
        model = XGBRegressor(**XGB_PARAMS)
        model.fit(X_train, y_train)
        
        # BÆ°á»›c 4: Predict nÄƒm N
        y_pred = model.predict(X_test)[0]
        
        # BÆ°á»›c 5: TÃ­nh sai lá»‡ch
        error_pct = abs(y_pred - y_real) / y_real * 100
        
        print(f"      Actual: {y_real:.2f}, Predicted: {y_pred:.2f}, Error: {error_pct:.2f}%")
        
        # BÆ°á»›c 6: LÆ°u káº¿t quáº£
        results.append({
            'year': year_n,
            'actual': y_real,
            'predicted': y_pred,
            'error_%': error_pct
        })
        
        # LÆ°u feature importance
        feature_importances.append({
            'year': year_n,
            **dict(zip(FEATURE_COLUMNS, model.feature_importances_))
        })
    
    print("-" * 80)
    
    # ===========================
    # 4. Táº O DATAFRAME Káº¾T QUáº¢
    # ===========================
    print("\nğŸ“Š Step 4: Creating results DataFrame...")
    
    results_df = pd.DataFrame(results)
    
    # TÃ­nh metrics tá»•ng há»£p
    y_actual = results_df['actual'].values
    y_predicted = results_df['predicted'].values
    
    mae_7y = mean_absolute_error(y_actual, y_predicted)
    rmse_7y = np.sqrt(mean_squared_error(y_actual, y_predicted))
    mape_7y = calculate_mape(y_actual, y_predicted)
    
    # LÆ°u CSV
    results_df.to_csv(BACKTEST_CSV, index=False)
    print(f"   âœ… Saved: {BACKTEST_CSV}")
    
    # ===========================
    # 5. Váº¼ BIá»‚U Äá»’
    # ===========================
    print("\nğŸ“ˆ Step 5: Creating plots...")
    
    # Biá»ƒu Ä‘á»“ 1: Actual vs Predicted
    plt.figure(figsize=(10, 6))
    plt.plot(results_df['year'], results_df['actual'], 'o-', 
             color='brown', linewidth=2, markersize=8, label='Actual')
    plt.plot(results_df['year'], results_df['predicted'], 's--', 
             color='blue', linewidth=2, markersize=8, label='Predicted')
    plt.fill_between(results_df['year'], 
                     results_df['predicted'] * 0.95, 
                     results_df['predicted'] * 1.05, 
                     alpha=0.2, color='blue', label='Â±5% band')
    plt.xlabel('NÄƒm', fontsize=12)
    plt.ylabel('NÄƒng suáº¥t (táº¥n/ha)', fontsize=12)
    plt.title('Walk-Forward Backtest: Actual vs Predicted (7 nÄƒm)', fontsize=14)
    plt.legend(loc='best')
    plt.grid(True, alpha=0.3)
    plt.xticks(results_df['year'])
    plt.tight_layout()
    plt.savefig(PLOT_ACTUAL_VS_PRED, dpi=150)
    plt.close()
    print(f"   âœ… Saved: {PLOT_ACTUAL_VS_PRED}")
    
    # Biá»ƒu Ä‘á»“ 2: Error (%) má»—i nÄƒm
    colors = ['green' if e < 5 else 'orange' if e < 10 else 'red' for e in results_df['error_%']]
    plt.figure(figsize=(10, 6))
    bars = plt.bar(results_df['year'], results_df['error_%'], color=colors, edgecolor='black')
    plt.axhline(y=mape_7y, color='red', linestyle='--', linewidth=2, label=f'MAPE = {mape_7y:.2f}%')
    plt.axhline(y=5, color='green', linestyle=':', linewidth=1.5, alpha=0.7, label='5% threshold')
    plt.xlabel('NÄƒm', fontsize=12)
    plt.ylabel('Error (%)', fontsize=12)
    plt.title('Walk-Forward Backtest: Prediction Error per Year', fontsize=14)
    plt.legend(loc='best')
    plt.grid(True, alpha=0.3, axis='y')
    plt.xticks(results_df['year'])
    # ThÃªm giÃ¡ trá»‹ trÃªn má»—i bar
    for bar, error in zip(bars, results_df['error_%']):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2, 
                 f'{error:.1f}%', ha='center', va='bottom', fontsize=10)
    plt.tight_layout()
    plt.savefig(PLOT_ERROR_PER_YEAR, dpi=150)
    plt.close()
    print(f"   âœ… Saved: {PLOT_ERROR_PER_YEAR}")
    
    # ===========================
    # 6. BÃO CÃO CUá»I CÃ™NG
    # ===========================
    print("\n" + "=" * 80)
    print("ğŸ“‹ BÃO CÃO WALK-FORWARD BACKTEST (7 NÄ‚M)")
    print("=" * 80)
    
    # Báº£ng káº¿t quáº£
    print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚  Year  â”‚ Actual  â”‚ Predicted â”‚ Error %  â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    for _, row in results_df.iterrows():
        print(f"â”‚  {int(row['year'])}  â”‚  {row['actual']:.2f}   â”‚   {row['predicted']:.2f}    â”‚   {row['error_%']:.2f}%  â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    # Metrics tá»•ng há»£p
    print(f"\nğŸ“Š METRICS Tá»”NG Há»¢P (7 NÄ‚M):")
    print(f"   â”œâ”€â”€ MAE:  {mae_7y:.4f} táº¥n/ha")
    print(f"   â”œâ”€â”€ RMSE: {rmse_7y:.4f} táº¥n/ha")
    print(f"   â””â”€â”€ MAPE: {mape_7y:.2f}%")
    
    # NÄƒm tá»‘t nháº¥t / kÃ©m nháº¥t
    best_year = results_df.loc[results_df['error_%'].idxmin()]
    worst_year = results_df.loc[results_df['error_%'].idxmax()]
    
    print(f"\nğŸ† NÄ‚M Dá»° BÃO Tá»T NHáº¤T:")
    print(f"   â””â”€â”€ {int(best_year['year'])}: Error = {best_year['error_%']:.2f}%")
    
    print(f"\nâš ï¸  NÄ‚M Dá»° BÃO KÃ‰M NHáº¤T:")
    print(f"   â””â”€â”€ {int(worst_year['year'])}: Error = {worst_year['error_%']:.2f}%")
    
    # Nháº­n xÃ©t tá»•ng quan
    print(f"\nğŸ’¡ NHáº¬N XÃ‰T Tá»”NG QUAN:")
    if mape_7y < 5:
        print(f"   âœ… MÃ´ hÃ¬nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c CAO (MAPE < 5%)")
        print(f"   âœ… PhÃ¹ há»£p cho dá»± bÃ¡o nÄƒng suáº¥t cÃ  phÃª thá»±c táº¿")
    elif mape_7y < 10:
        print(f"   âš ï¸  MÃ´ hÃ¬nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c TRUNG BÃŒNH (5% < MAPE < 10%)")
        print(f"   âš ï¸  CÃ³ thá»ƒ cáº£i thiá»‡n báº±ng thÃªm features hoáº·c tuning")
    else:
        print(f"   âŒ MÃ´ hÃ¬nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c THáº¤P (MAPE > 10%)")
        print(f"   âŒ Cáº§n xem xÃ©t láº¡i features vÃ  mÃ´ hÃ¬nh")
    
    # PhÃ¢n tÃ­ch thÃªm
    years_under_5pct = len(results_df[results_df['error_%'] < 5])
    print(f"\n   ğŸ“ˆ Sá»‘ nÄƒm cÃ³ error < 5%: {years_under_5pct}/7")
    print(f"   ğŸ“ˆ Error trung bÃ¬nh: {results_df['error_%'].mean():.2f}%")
    print(f"   ğŸ“ˆ Error cao nháº¥t: {results_df['error_%'].max():.2f}%")
    print(f"   ğŸ“ˆ Error tháº¥p nháº¥t: {results_df['error_%'].min():.2f}%")
    
    # Feature importance trung bÃ¬nh
    print(f"\nğŸ” FEATURE IMPORTANCE (TRUNG BÃŒNH 7 NÄ‚M):")
    fi_df = pd.DataFrame(feature_importances)
    mean_importance = fi_df[FEATURE_COLUMNS].mean().sort_values(ascending=False)
    for i, (feat, imp) in enumerate(mean_importance.items(), 1):
        print(f"   {i}. {feat}: {imp:.4f}")
    
    # Files Ä‘Ã£ lÆ°u
    print(f"\nğŸ“ FILES ÄÃƒ LÆ¯U:")
    print(f"   â”œâ”€â”€ {BACKTEST_CSV}")
    print(f"   â”œâ”€â”€ {PLOT_ACTUAL_VS_PRED}")
    print(f"   â””â”€â”€ {PLOT_ERROR_PER_YEAR}")
    
    print("\n" + "=" * 80)
    print("âœ… WALK-FORWARD BACKTEST COMPLETE â€” MODEL VALIDATED FOR 7 YEARS.")
    print("=" * 80)
    
    return {
        'results': results_df,
        'mae': mae_7y,
        'rmse': rmse_7y,
        'mape': mape_7y,
        'best_year': int(best_year['year']),
        'worst_year': int(worst_year['year'])
    }


if __name__ == "__main__":
    result = walk_forward_backtest()
